{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87ce2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "    File Name: CNN Trainer.ipynb\n",
    "    Author: Thomas Frew\n",
    "    Date created: 08/01/2023\n",
    "    Date last modified: 24/01/2023\n",
    "    Python Version: 3.11\n",
    "    \n",
    "    Reads \"Dataset.csv\", training data for a computer vision AI.\n",
    "    This can be in one of two forms:\n",
    "\n",
    "        - 2D: Images are labelled with coordinates, defining the center of some object of interest\n",
    "        - 4D: Images are labelled with coordinates, defining the bounding box around some object of interest\n",
    "\n",
    "    This data is then used to train a convolutional neural network\n",
    "    (CNN) with a preprogrammed architecture. Users can select the\n",
    "    number epochs the AI is trained for, visualise its training\n",
    "    progress and view its predictions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19316e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow for machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "\n",
    "# Import pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import cv2 for image manipulation\n",
    "import cv2\n",
    "\n",
    "# Import Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Import random for rnadomisation\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fe20f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first 5 rows of your dataset are:\n",
      "                                            Filename   x1  y1   x2  y2\n",
      "0  C:\\Users\\thoma\\OneDrive - University of Adelai...   88  35  103  50\n",
      "1  C:\\Users\\thoma\\OneDrive - University of Adelai...  122  42  138  62\n",
      "2  C:\\Users\\thoma\\OneDrive - University of Adelai...   75  24   92  42\n",
      "3  C:\\Users\\thoma\\OneDrive - University of Adelai...   70  13   87  37\n",
      "4  C:\\Users\\thoma\\OneDrive - University of Adelai...  144  67  170  98\n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset. This can be generated with \"2D Dataset Generator.ipynb or 4D Dataset Generator.ipynb\"\n",
    "dataset = pd.read_csv(\"Dataset.csv\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Store the number of dimensions in the training data\n",
    "output_dim = len(dataset.columns) - 1\n",
    "\n",
    "# If the training dataset is 2D, then we are tracking center points\n",
    "if (output_dim == 2):\n",
    "    dataset.columns = [\"Filename\",\"x\",\"y\"]\n",
    "    \n",
    "    # Visualise the first 5 rows of the dataset\n",
    "    print(\"The first 5 rows of your dataset are:\")\n",
    "    print(dataset.head())\n",
    "    \n",
    "# If the training dataset is 4D, then we are tracking bounding boxes\n",
    "elif (output_dim == 4):\n",
    "    dataset.columns = [\"Filename\",\"x1\",\"y1\",\"x2\",\"y2\"]\n",
    "\n",
    "    # Visualise the first 5 rows of the dataset\n",
    "    print(\"The first 5 rows of your dataset are:\")\n",
    "    print(dataset.head())\n",
    "    \n",
    "# Otherwise, something has gone wrong\n",
    "else:\n",
    "    print(\"Input data not in 2D (center-point) or 4D (bounding box) format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "47c149e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the image filenames (col 0) from their coordinate data (cols 1-2 or 1-4)\n",
    "coords = dataset.copy()\n",
    "file_names = coords.pop('Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "431476cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your images are 108 by 192 with 3 color channels.\n"
     ]
    }
   ],
   "source": [
    "# Load each file as its RGB image data\n",
    "image_data = []\n",
    "\n",
    "for fname in file_names:\n",
    "    image_data.append(cv2.imread(fname))\n",
    "    \n",
    "# Store the length and width of each image\n",
    "input_len, input_wid, channels = image_data[0].shape\n",
    "    \n",
    "# Report the image shape data\n",
    "print(f\"Your images are {input_len} by {input_wid} with {channels} color channels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d3f9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Convolutional Neural Network to predict the location of our centers/bounding boxes\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(input_len, input_wid, channels))) # Depends on inage size\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(400, activation='relu'))\n",
    "model.add(layers.Dense(100))\n",
    "model.add(layers.Dense(30))\n",
    "model.add(layers.Dense(output_dim)) # Depends on output dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dc77b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model's structure is:\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 106, 190, 128)     3584      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 53, 95, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 51, 93, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 25, 46, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 23, 44, 64)        36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 64768)             0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 400)               25907600  \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 100)               40100     \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                3030      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 124       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 26,065,158\n",
      "Trainable params: 26,065,158\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Visualise the model\n",
    "print(\"The model's structure is:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ec930d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training images and labels to numpy arrays\n",
    "image_data = np.asarray(image_data)\n",
    "coords = np.asarray(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01a2d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up data into training and testing with a 9:1 ratio\n",
    "datapoints = len(coords)\n",
    "split_index = int(datapoints*0.1)\n",
    "\n",
    "train_data = image_data[split_index:]\n",
    "test_data = image_data[:split_index]\n",
    "\n",
    "train_labels = coords[split_index:]\n",
    "test_labels = coords[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2399f9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many epochs do you want the CNN to be trained for?\n",
      ">> 1\n",
      "133/133 [==============================] - 162s 1s/step - loss: 526.4629 - accuracy: 0.8377 - val_loss: 90.3283 - val_accuracy: 0.9362\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.MeanSquaredError(),metrics=['accuracy'])\n",
    "epochs = int(input(\"How many epochs do you want the CNN to be trained for?\\n>> \"))\n",
    "\n",
    "history = model.fit(train_data, train_labels, epochs=epochs, validation_data=(test_data, test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "baac2598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you like to save this AI? (Y/n)\n",
      ">> Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI successfully saved.\n"
     ]
    }
   ],
   "source": [
    "# Ask the user if they would like to save the current model\n",
    "user_input = input(\"Would you like to save this AI as a file? (Y/n)\\n>> \")\n",
    "\n",
    "# If yes, save the model, to the current directory, in the folder \"Model\"\n",
    "if (user_input == 'Y'):\n",
    "    model.save(\"Model\")\n",
    "    print(\"AI successfully saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f93febab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1ba0b0b6e20>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation accuracy, over time\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.5, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "222009a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 3s 213ms/step\n"
     ]
    }
   ],
   "source": [
    "# Make the AI predict on all test data, and store these predictions\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8026db7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many training outputs would you like to see?\n",
      ">> 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of columns must be a positive integer, not 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [73]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m n_plots \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHow many training outputs would you like to see?\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>> \u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create an n x 1 subplot to display n tests\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_plots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m60\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the first 5 test images and the AI's guess as to where their center is\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,n_plots):\n\u001b[0;32m      9\u001b[0m               \n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Select a random test image, and display it\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:1435\u001b[0m, in \u001b[0;36msubplots\u001b[1;34m(nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw, **fig_kw)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1303\u001b[0m \u001b[38;5;124;03mCreate a figure and a set of subplots.\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1432\u001b[0m \n\u001b[0;32m   1433\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m fig \u001b[38;5;241m=\u001b[39m figure(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfig_kw)\n\u001b[1;32m-> 1435\u001b[0m axs \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubplots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1436\u001b[0m \u001b[43m                   \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubplot_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubplot_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1437\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mgridspec_kw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgridspec_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fig, axs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:896\u001b[0m, in \u001b[0;36mFigureBase.subplots\u001b[1;34m(self, nrows, ncols, sharex, sharey, squeeze, subplot_kw, gridspec_kw)\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gridspec_kw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    895\u001b[0m     gridspec_kw \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 896\u001b[0m gs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_gridspec(nrows, ncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mgridspec_kw)\n\u001b[0;32m    897\u001b[0m axs \u001b[38;5;241m=\u001b[39m gs\u001b[38;5;241m.\u001b[39msubplots(sharex\u001b[38;5;241m=\u001b[39msharex, sharey\u001b[38;5;241m=\u001b[39msharey, squeeze\u001b[38;5;241m=\u001b[39msqueeze,\n\u001b[0;32m    898\u001b[0m                   subplot_kw\u001b[38;5;241m=\u001b[39msubplot_kw)\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m axs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\figure.py:1395\u001b[0m, in \u001b[0;36mFigureBase.add_gridspec\u001b[1;34m(self, nrows, ncols, **kwargs)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m \u001b[38;5;124;03mReturn a `.GridSpec` that has this figure as a parent.  This allows\u001b[39;00m\n\u001b[0;32m   1358\u001b[0m \u001b[38;5;124;03mcomplex layout of Axes in the figure.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1391\u001b[0m \n\u001b[0;32m   1392\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1394\u001b[0m _ \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# pop in case user has added this...\u001b[39;00m\n\u001b[1;32m-> 1395\u001b[0m gs \u001b[38;5;241m=\u001b[39m GridSpec(nrows\u001b[38;5;241m=\u001b[39mnrows, ncols\u001b[38;5;241m=\u001b[39mncols, figure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1396\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gridspecs\u001b[38;5;241m.\u001b[39mappend(gs)\n\u001b[0;32m   1397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m gs\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\gridspec.py:385\u001b[0m, in \u001b[0;36mGridSpec.__init__\u001b[1;34m(self, nrows, ncols, figure, left, bottom, right, top, wspace, hspace, width_ratios, height_ratios)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhspace \u001b[38;5;241m=\u001b[39m hspace\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure \u001b[38;5;241m=\u001b[39m figure\n\u001b[1;32m--> 385\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mncols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    386\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mwidth_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth_ratios\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    387\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mheight_ratios\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheight_ratios\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\matplotlib\\gridspec.py:52\u001b[0m, in \u001b[0;36mGridSpecBase.__init__\u001b[1;34m(self, nrows, ncols, height_ratios, width_ratios)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     50\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of rows must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnrows\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ncols, Integral) \u001b[38;5;129;01mor\u001b[39;00m ncols \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of columns must be a positive integer, not \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mncols\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nrows, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ncols \u001b[38;5;241m=\u001b[39m nrows, ncols\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_height_ratios(height_ratios)\n",
      "\u001b[1;31mValueError\u001b[0m: Number of columns must be a positive integer, not 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x4320 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ask the user how many test evaluations they would like to see\n",
    "n_plots = int(input(\"How many training outputs would you like to see? (≥2)\\n>> \")\n",
    "\n",
    "# Create an n x 1 subplot to display n tests\n",
    "fig, axes = plt.subplots(1, n_plots, figsize=(15, 60)) \n",
    "\n",
    "# Display the first 5 test images and the AI's guess as to where their center is\n",
    "for i in range(0,n_plots):\n",
    "              \n",
    "    # Select a random test image, and display it\n",
    "    randi = random.randrange(split_index)\n",
    "    axes[i].imshow(test_data[randi])\n",
    "\n",
    "    # If the AI should detect the center of some object of interest...\n",
    "    if (output_dim == 2):\n",
    "        # Create a patch and place it in the center of the image\n",
    "        pred_point = patches.Rectangle((predictions[i][0], predictions[i][1]), 2, 2, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        axes[i].add_patch(pred_point)\n",
    "\n",
    "        true_point = patches.Rectangle((test_labels[i][0], test_labels[i][1]), 2, 2, linewidth=2, edgecolor='b', facecolor='none')\n",
    "        axes[i].add_patch(true_point)\n",
    "              \n",
    "    # If the AI should detect a bounding box around some object of interest...\n",
    "    elif (output_dim == 4):\n",
    "              \n",
    "        # Create a red bounding box around where the AI thinks the object is\n",
    "        pred_len = predictions[randi][2] - predictions[randi][0]\n",
    "        pred_wid = predictions[randi][3] - predictions[randi][1]\n",
    "\n",
    "        pred_box = patches.Rectangle((predictions[randi][0], predictions[randi][1]), pred_len, pred_wid, linewidth=2, edgecolor='r', facecolor='none')\n",
    "        axes[i].add_patch(pred_box)\n",
    "\n",
    "        # Create a blue bounding box around where the object actually is\n",
    "        true_len = test_labels[randi][2] - test_labels[randi][0]\n",
    "        true_wid = test_labels[randi][3] - test_labels[randi][1]\n",
    "\n",
    "        true_box = patches.Rectangle((test_labels[randi][0], test_labels[randi][1]), true_len, true_wid, linewidth=2, edgecolor='b', facecolor='none')\n",
    "        axes[i].add_patch(true_box)\n",
    "\n",
    "    # Otherwise, something has gone wrong\n",
    "    else:\n",
    "        print(\"Input data not in 2D (center-point) or 4D (bounding box) format.\")\n",
    "        \n",
    "# Create a legend for the plot, automatically positioned\n",
    "plt.legend(['Prediction', 'Ground Truth'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e8a549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b21d6e54",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
