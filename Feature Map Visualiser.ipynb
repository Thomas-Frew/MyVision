{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "    File Name: Feature Map Visualiser.ipynb\n",
    "    Author: Thomas Frew\n",
    "    Date created: 08/01/2023\n",
    "    Date last modified: 24/01/2023\n",
    "    Python Version: 3.11\n",
    "    \n",
    "    Reads \"Dataset.csv\", training data for a computer vision AI.\n",
    "    This can be in one of two forms:\n",
    "\n",
    "        - 2D: Images are labelled with coordinates, defining the center of some object of interest\n",
    "        - 4D: Images are labelled with coordinates, defining the bounding box around some object of interest\n",
    "\n",
    "    This data is then used with an existing CNN, to visualise\n",
    "    that CNN's feature maps. Feature maps represent how the\n",
    "    AI \"sees\" an image.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac716981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tensorflow for machine learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models\n",
    "\n",
    "# Import pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import cv2 for image manipulation\n",
    "import cv2\n",
    "\n",
    "# Import Matplotlib for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import random for rnadomisation\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe20f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training dataset. This can be generated with \"2D Dataset Generator.ipynb or 4D Dataset Generator.ipynb\"\n",
    "dataset = pd.read_csv(\"Dataset.csv\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Store the number of dimensions in the training data\n",
    "output_dim = len(dataset.columns) - 1\n",
    "\n",
    "# If the training dataset is 2D, then we are tracking center points\n",
    "if (output_dim == 2):\n",
    "    dataset.columns = [\"Filename\",\"x\",\"y\"]\n",
    "    \n",
    "    # Visualise the first 5 rows of the dataset\n",
    "    print(\"The first 5 rows of your dataset are:\")\n",
    "    print(dataset.head())\n",
    "    \n",
    "# If the training dataset is 4D, then we are tracking bounding boxes\n",
    "elif (output_dim == 4):\n",
    "    dataset.columns = [\"Filename\",\"x1\",\"y1\",\"x2\",\"y2\"]\n",
    "\n",
    "    # Visualise the first 5 rows of the dataset\n",
    "    print(\"The first 5 rows of your dataset are:\")\n",
    "    print(dataset.head())\n",
    "    \n",
    "# Otherwise, something has gone wrong\n",
    "else:\n",
    "    print(\"Input data not in 2D (center-point) or 4D (bounding box) format.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c149e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the image filenames (col 0) from their coordinate data (cols 1-2 or 1-4)\n",
    "coords = dataset.copy()\n",
    "file_names = coords.pop('Filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431476cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load each file as its RGB image data\n",
    "image_data = []\n",
    "\n",
    "for fname in file_names:\n",
    "    image_data.append(cv2.cvtColor(cv2.imread(fname), cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "# Store the length and width of each image\n",
    "input_len, input_wid, channels = image_data[0].shape\n",
    "    \n",
    "# Report the image shape data\n",
    "print(f\"Your images are {input_len} by {input_wid} with {channels} color channels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f9471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the AI model created in \"CNN Trainer.ipynb\"\n",
    "model = models.load_model(\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc77b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the model\n",
    "print(\"The model's structure is:\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec930d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the training images and labels to numpy arrays\n",
    "image_data = np.asarray(image_data)\n",
    "coords = np.asarray(coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a2d026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split up data into training and testing with a 9:1 ratio\n",
    "datapoints = len(coords)\n",
    "split_index = int(datapoints*0.1)\n",
    "\n",
    "train_data = image_data[split_index:]\n",
    "test_data = image_data[:split_index]\n",
    "\n",
    "train_labels = coords[split_index:]\n",
    "test_labels = coords[:split_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b27e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store and show the names of layers in the CNN\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "\n",
    "print(\"The CNN's layer are:\")\n",
    "print(layer_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature map model from CNN I/O\n",
    "layer_outputs = [layer.output for layer in model.layers]\n",
    "feature_map_model = tf.keras.models.Model(model.input, layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405c0dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the user to input the maximum number of feature maps they want to view, per layer\n",
    "max_consecutive = int(input(\"How many feature maps would you like to view on each layer? (Reccomended: 3-7) \\n>> \"))\n",
    "\n",
    "# Select a random image to process through the CNN\n",
    "mapped_image = test_data[random.randrange(split_index) - 1]\n",
    "mapped_image = np.expand_dims(mapped_image, axis=0)\n",
    "\n",
    "# Create the feature maps for that particular image\n",
    "feature_maps = feature_map_model.predict(mapped_image)\n",
    "\n",
    "# Find the number of convolutional layers\n",
    "conv_layers = 0;\n",
    "for layer_name, feature_map in zip(layer_names, feature_maps):  \n",
    "    if len(feature_map.shape) == 4:\n",
    "        conv_layers += 1;\n",
    "\n",
    "# Create a plot to display CNN feature maps\n",
    "fig, axes = plt.subplots(conv_layers, 1, figsize=(15, 15)) \n",
    "\n",
    "# Layer index iterator\n",
    "layer_i = 0\n",
    "\n",
    "# Visualise all \"interesting\" (non-empty) feature maps\n",
    "for layer_name, feature_map in zip(layer_names, feature_maps):  \n",
    "    if len(feature_map.shape) == 4:\n",
    "        \n",
    "        # Define a stack of images in the same layer\n",
    "        image_stack = []\n",
    "        \n",
    "        # Number of images in the layer\n",
    "        k = feature_map.shape[-1]  \n",
    "        \n",
    "        # Counter for the number of \"interesting\" feature maps\n",
    "        accepted = 0\n",
    "        \n",
    "        # Feature map iterator\n",
    "        imap_i = 0\n",
    "        \n",
    "        # We collect interesting feature maps until we have enough or we run out of maps\n",
    "        while (accepted < max_consecutive and imap_i < k):\n",
    "            feature_image = feature_map[0, :, :, imap_i]\n",
    "            maximum = np.max(feature_image)\n",
    "            mean = np.mean(feature_image)\n",
    "            \n",
    "            if (mean > 0):\n",
    "                feature_image *= 255/(maximum+1)\n",
    "                image_stack.append(feature_image)\n",
    "                \n",
    "                accepted += 1\n",
    "                \n",
    "            imap_i += 1\n",
    "\n",
    "        # Show our set of selected feature maps\n",
    "        axes[layer_i].set_title(layer_name)\n",
    "        axes[layer_i].grid(False)\n",
    "        axes[layer_i].imshow(np.concatenate(image_stack, axis=1))\n",
    "        layer_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6127bde2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede358d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
